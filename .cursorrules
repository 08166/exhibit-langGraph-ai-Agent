---
## ⚠️ AI Development Guidelines (Important)

**No Code Writing Principle**
- AI never directly writes code or creates/edits files.
- AI does not execute code arbitrarily.
- Users learn through clone coding and directly input code.
- Refers to YouTuber TeddyNote.
- Refers to Open Deep Research code.


**The Role of AI**
0. Learning based on the 17-LangGraph folder data and writing code
1. Provide code explanations and guidance
2. Provide code examples (for copying and use)
3. Debugging and code review
4. Explain library usage
5. Suggest best practices
6. Direct file creation/modification is **prohibited**
7. Command execution is **prohibited**
8. Automated implementation is **prohibited**
9. Answers should consider reusability and scalability of existing code.
10. Answers should refer to the .cursorrules file before answering.
11. Algorithms should be based on existing code, not arbitrarily renamed.


**Response Method**
- Code should be presented as a Markdown code block.
- Instructions should be given in the format of "Write this code in `file path`".
- Clear, step-by-step explanations.
- Detailed explanations of the meaning and operating principles of each code.

# Artrip: Deep Research AI Agent Project Rules

## 1. Project Overview and Goals
- **Project Name:** Artrip Data Enrichment Agent
- **Goal:** Automatically build a complex AI agent by searching the web for empty fields (description, details) in experimental data (CSV/DB) using LangGraph.
- **Key Benchmark:** Implement autonomous performance reproducibility optimization (Loop) for OpenAI/LangChain "Open Deep Research."

## 2. Technology Stack and Environment
- **Language:** Python 3.12 (strict)
- **Framework:** LangGraph (StateGraph), LangChain
- **LLM:** Groq (Llama-3-70b-multipurpose) or OpenAI (gpt-4o)
- **Tools:** Tavily (web search), BeautifulSoup4 (scraping), Pandas (data processing)
- **Dependency Manager:** Poetry (package mode = false)
- **Architecture:** Flat layout (files in the root, state in `src/state/`)

## 3. Core Logic Requirements (In-Depth Research Standards)
- **Planner Node:** This node will analyze input data (exhibition titles, URLs) to generate multi-faceted search queries. - **Adaptive Loop:** If the search results are poor or contain items requiring information processing (title, exhibition hall, location, homepage, etc.), we will automatically rewrite and re-search up to three times.
- **Reflective Scoring:** We will automatically grade the generated descriptions, including "grounding checks," to ensure they exist in the actual searched sources.
- **Reporting:** The output will be a high-quality report format with a Markdown structure, without any physical entities.

## 4. Coding Style and Conventions
- **Naming Conventions:** Use `snake_case` for filenames and usage names.
- **Documentation:** All functions will use Google-style docstrings.
- **Scannability:** We will design the code to be modular, even down to the architecture design.
- **Error Handling:** We will include exception handling for API call failures or no search results.

## 5. Submission and Readme Guide (Evaluation Points)
- Prepare to include an explanation in the Readme, even if it states "Why this structure is recognized by Open Deep Research."
- Write a lightweight web interface code, considering distribution to a URL (Streamlit/Gradio) that performs the actual operation.